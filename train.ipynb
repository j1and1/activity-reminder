{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "First lets check for dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a folder with pictures that contain the clear background, me standing in diferent positions/camera angles, me squatting from different angles. The following section of code is just to convert those images to training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def list_dir(path):\n",
    "    folder_content = []\n",
    "    for p in os.listdir(path):\n",
    "        full_path = f'{path}/{p}'\n",
    "        if os.path.isdir(full_path):\n",
    "            folder_content.extend(list_dir(full_path))\n",
    "        else:\n",
    "            folder_content.append(full_path)\n",
    "    return folder_content\n",
    "\n",
    "un_preped = list_dir('data/un_prep')\n",
    "\n",
    "list_iterator = iter(un_preped)\n",
    "next(list_iterator)\n",
    "bg_path = str(un_preped[0])\n",
    "\n",
    "background = cv2.imread(bg_path)\n",
    "background = cv2.fastNlMeansDenoisingColored(background, None, 10, 10, 7, 21)\n",
    "\n",
    "for idx in list_iterator:\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "    \n",
    "    for _ in range(500):\n",
    "        backSub.apply(background)\n",
    "\n",
    "    fg = cv2.imread(idx)\n",
    "    fg = cv2.fastNlMeansDenoisingColored(fg, None, 10, 10, 7, 21)\n",
    "    \n",
    "    mask = backSub.apply(fg)\n",
    "    mask = cv2.dilate(mask, None, 3)\n",
    "    # show masked image\n",
    "    cv2.imshow('Masked out', mask)\n",
    "    cv2.imwrite('test.jpg', mask)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "#release resources\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
